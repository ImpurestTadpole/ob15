# LeMelon - Dual SO-ARM100 Mobile Manipulator

A comprehensive mono-repo for building, controlling, and training a dual-arm mobile manipulator using ROS2, VR teleoperation, and machine learning.

## ğŸš€ Quick Start

```bash
# Clone the repository with submodules
git clone --recursive https://github.com/ImpurestTadpole/lemelon.git
cd lemelon

# Run the setup script
./scripts/setup_env.sh

# Build the ROS2 workspace
./scripts/build_ros.sh

# Start data collection
./scripts/collect_real.sh
```

## ğŸ“ Project Structure

```
LeMelon/
â”œâ”€â”€ external/                            # External repos cloned/submoduled
â”‚   â”œâ”€â”€ lerobot/                         # HuggingFace's LeRobot
â”‚   â”œâ”€â”€ leisaac/                         # Lightwheel's Isaac-based envs
â”‚   â”œâ”€â”€ lekkiwi/                         # LeKiwi platform repo (UIUC)
â”‚   â”œâ”€â”€ so_arm_100/                      # SO-100 URDF/control
â”‚   â”œâ”€â”€ lightwheel_kitchen/             # Scene/env reference
â”‚   â””â”€â”€ collab-sim/                     # NVLabs dataset / RL tools
â”‚
â”œâ”€â”€ src/                                 # Main source code for LeMelon
â”‚   â”œâ”€â”€ lemelon_description/            # URDFs, meshes, XACROs for full robot
â”‚   â”œâ”€â”€ lemelon_bringup/                # ROS2 launch files to start system
â”‚   â”œâ”€â”€ lemelon_teleop/                 # VR control nodes + Quest 3 integration
â”‚   â”œâ”€â”€ lemelon_interfaces/             # Custom ROS2 msgs/srvs
â”‚   â””â”€â”€ lemelon_utils/                  # Shared utils: transforms, kinematics, logging
â”‚
â”œâ”€â”€ training/                            # Model training and sim scripts
â”‚   â”œâ”€â”€ configs/                        # YAML configs for RL and BC
â”‚   â”œâ”€â”€ ppo/                            # PPO-based training envs (IsaacLab + LeRobot)
â”‚   â”œâ”€â”€ diffusion/                      # Diffusion policy training scripts
â”‚   â””â”€â”€ eval/                           # Evaluation pipelines and benchmarks
â”‚
â”œâ”€â”€ data/                                # Raw and processed data
â”‚   â”œâ”€â”€ real/                           # Collected from teleop + cameras
â”‚   â”œâ”€â”€ sim/                            # Sim-collected trajectories
â”‚   â””â”€â”€ processed/                      # HDF5 or Datasets for training
â”‚
â”œâ”€â”€ deploy/                              # Onboard tools and scripts
â”‚   â”œâ”€â”€ jetson/                         # Jetson Nano setup for inference
â”‚   â””â”€â”€ rpi/                            # Raspberry Pi tools for remote ops
â”‚
â”œâ”€â”€ ros2_ws/                             # ROS2 workspace overlay
â”‚   â””â”€â”€ src/ â†’ symlink to ../src/
â”‚
â”œâ”€â”€ scripts/                             # Top-level utilities and run scripts
â”‚   â”œâ”€â”€ setup_env.sh                    # Setup conda/venv and install deps
â”‚   â”œâ”€â”€ build_ros.sh                    # ROS2 build helper
â”‚   â”œâ”€â”€ collect_real.sh                 # Real world data collection launch
â”‚   â”œâ”€â”€ collect_sim.sh                  # Sim collection + teleop launch
â”‚   â””â”€â”€ train_model.sh                  # Unified training entrypoint
â”‚
â”œâ”€â”€ env/                                 # Conda or venv environment files
â”‚   â”œâ”€â”€ environment.yml
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ .gitmodules                          # Git submodule definitions
â”œâ”€â”€ README.md
â””â”€â”€ pyproject.toml (optional if using poetry)
```

## ğŸ—ï¸ System Architecture

- **Hardware**: Dual 650mm SO-ARM100 arms on LeKiwi omnidirectional base
- **Sensors**: Three cameras (left/right wrist monocular, chest RGB-D)
- **Teleoperation**: Meta Quest 3 WebXR application for real-time control
- **Data Pipeline**: Real-world and simulated data collection for ML training
- **Compute**: Distributed (training on PC, inference on Jetson Nano/Raspberry Pi)

## ğŸ“‹ Prerequisites

- Ubuntu 22.04 LTS
- ROS2 Humble
- Python 3.10+
- Meta Quest 3 (for teleoperation)
- NVIDIA GPU (for training)

## ğŸ”§ Installation

See [SETUP_GUIDE.md](docs/SETUP_GUIDE.md) for detailed installation instructions.

## ğŸ® Usage

### Data Collection
```bash
# Start real-world data collection with Quest 3
./scripts/collect_real.sh

# Start simulation data collection
./scripts/collect_sim.sh
```

### Training
```bash
# Train a model on collected data
./scripts/train_model.sh --config training/configs/ppo_config.yaml
```

### Deployment
```bash
# Deploy to Jetson Nano
./deploy/jetson/deploy_model.sh --model path/to/trained/model
```

## ğŸ“š Documentation

- [Setup Guide](docs/SETUP_GUIDE.md) - Complete installation and configuration
- [Hardware Integration](docs/HARDWARE.md) - Robot assembly and wiring
- [Teleoperation](docs/TELEOP.md) - VR control setup and usage
- [Training](docs/TRAINING.md) - ML model training and evaluation
- [Deployment](docs/DEPLOYMENT.md) - Edge deployment guide

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [LeRobot](https://github.com/huggingface/lerobot) - Robot learning framework
- [LeKiwi](https://github.com/SIGRobotics-UIUC/LeKiwi) - Mobile base platform
- [SO-ARM100](https://github.com/TheRobotStudio/SO-ARM100) - Robotic arm
- [IsaacLab](https://github.com/isaac-sim/IsaacLab) - Simulation environment 
